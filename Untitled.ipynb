{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "false-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f445af78640>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "potential-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    \n",
    "    \n",
    "def data_map(path):\n",
    "    dmap = {}\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if files:\n",
    "            k = os.path.split(root)[-1]\n",
    "            k = int(k.split('_')[0])\n",
    "            dmap[k] = np.array([os.path.join(root, f) for f in files])\n",
    "            \n",
    "    return dmap\n",
    "\n",
    "\n",
    "def get_mean_std(dmap):\n",
    "    resize = transforms.Resize((64, 64))\n",
    "    n_samples = sum([len(v) for v in dmap.values()])\n",
    "    images = torch.zeros((n_samples, 3, 64, 64), dtype=torch.float32)\n",
    "    \n",
    "    idx = 0\n",
    "    for samples in dmap.values():\n",
    "        for path in samples:\n",
    "            img = cv2.imread(path)[:, :, ::-1].copy()\n",
    "            img = torch.tensor(img)\n",
    "            img = torch.permute(img, (2, 0, 1))\n",
    "            img = resize(img)\n",
    "            images[idx] = img\n",
    "            idx += 1\n",
    "    \n",
    "    images = images.reshape(3, -1)\n",
    "    return images.mean(dim=-1), images.std(dim=-1)\n",
    "\n",
    "\n",
    "def kfold_splitter(dmap, *, k, shuffle=False):\n",
    "    \n",
    "    if shuffle:\n",
    "        dmap_new = {}\n",
    "        for cls, samples in dmap.items():\n",
    "            temp = samples.copy()\n",
    "            np.random.shuffle(temp)\n",
    "            dmap_new[cls] = temp\n",
    "            \n",
    "        dmap = dmap_new\n",
    "        \n",
    "    num_samples_in_fold_per_cls = {cls: math.ceil(len(samples) / k) for cls, samples in dmap.items()}\n",
    "    \n",
    "    for fold in range(k):\n",
    "        train_folds = {}\n",
    "        test_fold = {}\n",
    "        \n",
    "        for cls, samples in dmap.items():\n",
    "            num_in_fold = num_samples_in_fold_per_cls[cls]\n",
    "            \n",
    "            all_idx = np.arange(len(samples))\n",
    "            idx_in = (fold * num_in_fold <= all_idx) & (all_idx < (fold + 1) * num_in_fold)\n",
    "            idx_out = ~idx_in\n",
    "            \n",
    "            train_folds[cls] = samples[idx_out].copy()\n",
    "            test_fold[cls] = samples[idx_in].copy()\n",
    "\n",
    "        yield train_folds, test_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "hindu-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_map('data/cifar-100_5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "04b34c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = kfold_splitter(a, k=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "streaming-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataSet(Dataset):\n",
    "    def __init__(self, data_map, mean, std, data_transforms, preload=False):\n",
    "        self.data = data_map\n",
    "        self.transform = data_transforms\n",
    "        self._len = sum([len(v) for v in self.data.values()])\n",
    "        self.classes = list(sorted(self.data.keys()))\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.cache = None\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "        if preload:\n",
    "            self.load_all()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self._len:\n",
    "            if self.cache is None:\n",
    "                image, label = self.load_item_from_disk(idx)\n",
    "            else:\n",
    "                image, label = self.load_item_from_ram(idx)\n",
    "        \n",
    "        else:\n",
    "            raise IndexError(f\"Index {idx:,} is out of range for dataset with length {self._len:,}\")\n",
    "            \n",
    "        # Augment, to-tensor\n",
    "        image = self.transform(image)\n",
    "        image = self.normalize(image)\n",
    "        label = torch.tensor(label, device=self.device)\n",
    "        \n",
    "        image = image.to(self.device)\n",
    "        return image, label\n",
    "\n",
    "        \n",
    "    def load_all(self):\n",
    "        self.cache = {}\n",
    "        for idx in tqdm(range(self._len), desc='Loading data', ncols=100):\n",
    "            item = self.load_item_from_disk(idx)\n",
    "            self.cache[idx] = item\n",
    "            \n",
    "    def load_item_from_disk(self, idx):\n",
    "        for cls, samples in self.data.items():\n",
    "            if idx < len(samples):\n",
    "                item = {'X': samples[idx], 'y': cls}\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                idx -= len(samples)\n",
    "        \n",
    "        image = cv2.imread(item['X'])[:, :, ::-1].copy()\n",
    "        label = item['y']\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "    def load_item_from_ram(self, idx):\n",
    "        temp, label = self.cache[idx]\n",
    "        image = temp.copy()\n",
    "        return image, label\n",
    "    \n",
    "    def normalize(self, image):\n",
    "        return (image - self.mean) / (self.std + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trial, dmap, transforms, scorer):\n",
    "    \n",
    "    # optuna suggestions..\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for idx, (train, test) in enumerate(kfold_splitter(dmap, k=3)):\n",
    "        \n",
    "        mean, std = get_mean_std(train)\n",
    "        \n",
    "        train_dset = ImageDataSet(train, mean, std, data_transforms=transforms['train'], preload=True)\n",
    "        test_dset = ImageDataSet(test, mean, std, data_transforms=transforms['test'], preload=True)\n",
    "        \n",
    "        train_loader = DataLoader(train_dset, batch_size=?, shuffle=True, num_workers=8)\n",
    "        test_loader = DataLoader(test_dset, batch_size=?, num_workers=8)\n",
    "        \n",
    "        model = ...  # get model\n",
    "        \n",
    "        fold_score = fit_and_evaluate(model, train_loader, test_loader, scorer, epochs=?)       \n",
    "        scores.append(fold_score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def fit_and_evaluate(model, train, test, scorer, epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2590f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d1d6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 10 * 3 * 50 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1235ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/vgg-cats/0_Abyssinian/34.jpg\n",
      "data/vgg-cats/8_Egyptian_Mau/145.jpg\n",
      "data/vgg-cats/8_Egyptian_Mau/191.jpg\n",
      "data/vgg-cats/8_Egyptian_Mau/139.jpg\n",
      "data/vgg-cats/8_Egyptian_Mau/177.jpg\n",
      "data/vgg-cats/8_Egyptian_Mau/167.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: Ignoring iCCP chunk with declared size = 150472 and actual length = 19400\n"
     ]
    }
   ],
   "source": [
    "bad_data = []\n",
    "\n",
    "for root, dirs, files in os.walk('data'):\n",
    "    for f in files:\n",
    "        fname = os.path.join(root, f)\n",
    "        loaded = cv2.imread(fname)\n",
    "        if loaded is None:\n",
    "            print(fname)\n",
    "            bad_data.append(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
