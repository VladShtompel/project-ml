{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "covered-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        res = pickle.load(fo, encoding='bytes')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-contact",
   "metadata": {},
   "source": [
    "## cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developmental-joshua",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:21, 2331.04it/s]\n",
      "10000it [00:04, 2237.91it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = unpickle('data/cifar-100-python/meta')\n",
    "\n",
    "fine_label_names = [t.decode('utf8') for t in meta[b'fine_label_names']]\n",
    "\n",
    "train = unpickle('data/cifar-100-python/train')\n",
    "\n",
    "filenames = [t.decode('utf8') for t in train[b'filenames']]\n",
    "fine_labels = train[b'fine_labels']\n",
    "data = train[b'data']\n",
    "\n",
    "images = list()\n",
    "for d in data:\n",
    "    image = np.zeros((32,32,3), dtype=np.uint8)\n",
    "    image[...,0] = np.reshape(d[:1024], (32,32)) # Red channel\n",
    "    image[...,1] = np.reshape(d[1024:2048], (32,32)) # Green channel\n",
    "    image[...,2] = np.reshape(d[2048:], (32,32)) # Blue channel\n",
    "    images.append(image)\n",
    "\n",
    "for index,image in tqdm(enumerate(images)):\n",
    "    filename = filenames[index]\n",
    "    label = fine_labels[index]\n",
    "    label = fine_label_names[label]\n",
    "    os.makedirs(f'data/cifar-100/{label}', exist_ok=True)\n",
    "    plt.imsave(f'data/cifar-100/{label}/{filename}', image)\n",
    "\n",
    "test = unpickle('data/cifar-100-python/test')\n",
    "filenames = [t.decode('utf8') for t in test[b'filenames']]\n",
    "fine_labels = test[b'fine_labels']\n",
    "data = test[b'data']\n",
    "\n",
    "images = list()\n",
    "for d in data:\n",
    "    image = np.zeros((32,32,3), dtype=np.uint8)\n",
    "    image[...,0] = np.reshape(d[:1024], (32,32)) # Red channel\n",
    "    image[...,1] = np.reshape(d[1024:2048], (32,32)) # Green channel\n",
    "    image[...,2] = np.reshape(d[2048:], (32,32)) # Blue channel\n",
    "    images.append(image)\n",
    "\n",
    "for index,image in tqdm(enumerate(images)):\n",
    "    filename = filenames[index]\n",
    "    label = fine_labels[index]\n",
    "    label = fine_label_names[label]\n",
    "    os.makedirs(f'data/cifar-100/{label}', exist_ok=True)\n",
    "    plt.imsave(f'data/cifar-100/{label}/{filename}', image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-lunch",
   "metadata": {},
   "source": [
    "## coil100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pending-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7180/7180 [00:00<00:00, 45139.18it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'data/coil-100'\n",
    "\n",
    "for img in tqdm(os.listdir(path)):\n",
    "    if img.endswith('png'):\n",
    "        label, fname = img.split('__')\n",
    "        orig = os.path.join(path, img)\n",
    "        cls_fold = os.path.join(path, label)\n",
    "        new = os.path.join(cls_fold, fname)\n",
    "        os.makedirs(cls_fold, exist_ok=True)\n",
    "        os.rename(orig, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-petersburg",
   "metadata": {},
   "source": [
    "## vgg-cats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demanding-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [00:00<00:00, 41736.44it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'data/vgg-cats/'\n",
    "\n",
    "for img in tqdm(os.listdir(path)):\n",
    "    if img.endswith('jpg'):\n",
    "        *label, fname = img.split('_')\n",
    "        label = '_'.join(label)\n",
    "        orig = os.path.join(path, img)\n",
    "        cls_fold = os.path.join(path, label)\n",
    "        new = os.path.join(cls_fold, fname)\n",
    "        os.makedirs(cls_fold, exist_ok=True)\n",
    "        os.rename(orig, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-pantyhose",
   "metadata": {},
   "source": [
    "## cinic10\n",
    "\n",
    "prune 90% of the data (huge dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "upset-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/CINIC-10'\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    images = os.listdir(os.path.join(path, folder))\n",
    "    np.random.shuffle(images)\n",
    "    prune_num = int(len(images) * 0.9)\n",
    "    [os.remove(os.path.join(path, folder, img)) for img in images[:prune_num]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-stream",
   "metadata": {},
   "source": [
    "# Data splits: \n",
    "\n",
    "* cinic-10: Split in 2\n",
    "* cifar-100: Split in 5\n",
    "* coil-100: split in 5\n",
    "* stanford-dogs: split in 6\n",
    "* vgg-cats\n",
    "* flowers\n",
    "\n",
    "\n",
    "Total: 20 datasets, 125k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "earlier-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = [('data/cifar-100', 5),\n",
    "               ('data/coil-100', 5),\n",
    "               ('data/stanford-dogs', 6),\n",
    "               ('data/CINIC-10', 2)]\n",
    "\n",
    "\n",
    "for data_folder, num_splits in data_splits:\n",
    "    \n",
    "    all_classes = os.listdir(data_folder)\n",
    "    num_classes = len(all_classes)\n",
    "    np.random.shuffle(all_classes)\n",
    "    \n",
    "    for idx in range(num_splits):\n",
    "        new_folder = f\"{data_folder}_{idx + 1}\"\n",
    "        os.makedirs(new_folder, exist_ok=True)\n",
    "        \n",
    "        classes = all_classes[idx * (num_classes // num_splits):(idx + 1) * (num_classes // num_splits)]\n",
    "        \n",
    "        old_paths = [os.path.join(data_folder, cls) for cls in classes]\n",
    "        new_paths = [os.path.join(new_folder, cls) for cls in classes]\n",
    "\n",
    "        [shutil.move(src, dst) for src, dst in zip(old_paths, new_paths)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
